11. Qu√© datos externos agregar√≠a en este dataset que mejorar√≠a el an√°lisis de los datos
¬°Gran pregunta! Los datos actuales nos dicen qu√© pas√≥, pero no por qu√©. Yo agregar√≠a:

Datos Meteorol√≥gicos (Clima): üå¶Ô∏è Unir por fecha y aeropuerto (local). Esto nos permitir√≠a responder preguntas como: "¬øCu√°ntos vuelos se cancelaron o demoraron por baja visibilidad, viento o lluvia?".

Feriados y Eventos: üìÖ Una tabla simple de fechas (fecha, descripcion_evento). Esto ayudar√≠a a explicar los picos de pasajeros (ej. "Inicio de vacaciones de invierno", "Feriado de Carnaval").

Datos Econ√≥micos (Inflaci√≥n/D√≥lar): üí∏ Unir por fecha. Esto ayudar√≠a a correlacionar la cantidad de pasajeros con el poder adquisitivo. ¬øSube el d√≥lar y bajan los pasajeros?

Detalle de Aeronaves: ‚úàÔ∏è Unir por aeronave. Una tabla que diga la capacidad m√°xima de cada modelo de avi√≥n. Con esto, podr√≠amos calcular el porcentaje de ocupaci√≥n (pasajeros / capacidad_maxima), una m√©trica clave para las aerol√≠neas.

12. Elabore sus conclusiones y recomendaciones sobre este proyecto
Conclusiones:

El stack tecnol√≥gico (Airflow > Spark > Hive) fue validado y demostr√≥ ser robusto para un proceso ETL de Big Data.

La limpieza de datos (Spark) fue esencial: Los datos crudos (CSV) ten√≠an problemas cr√≠ticos que Hive no pod√≠a manejar solo (delimitadores incorrectos, fechas nulas, nombres de columna con espacios). El uso de Spark para transformar los datos fue un √©xito.

Airflow es clave para la automatizaci√≥n: El DAG asegura que el proceso sea repetible, confiable y que cada paso se ejecute en el orden correcto. El historial de logs fue fundamental para la depuraci√≥n.

Hive es una gran capa anal√≠tica: Una vez procesados los datos, Hive nos da el poder de usar SQL para an√°lisis complejos (como los JOINs y GROUP BYs que hicimos) sobre archivos que viven en HDFS.

Recomendaciones:

Monitoreo de Calidad de Datos: Implementar "data checks" en el DAG de Airflow (ej. usando el SQLCheckOperator). Por ejemplo, una tarea que verifique que SUM(pasajeros) sea mayor a cero. Si falla, el DAG se detiene y avisa.

Estandarizar Nombres de Columnas: El mayor problema que tuvimos fue adivinar los nombres de las columnas (Clasificaci√≥n Vuelo vs clasificacion_de_vuelo). Si es posible, se debe exigir que los archivos CSV siempre vengan con los mismos nombres estandarizados (ej. todo en min√∫scula y con _).

Pasar a Parquet: El script de Spark actualmente guarda en Hive en el formato por defecto (texto). Ser√≠a mucho m√°s eficiente si Spark guardara los datos limpios en formato Parquet (df_vuelos_clean.write.format("parquet")...). Es m√°s r√°pido para consultar y ocupa mucho menos espacio.

13. Proponer una arquitectura alternativa para este proceso (Cloud)
La arquitectura que usaste es un "stack" On-Premise cl√°sico. Una alternativa moderna usando Cloud (Google Cloud - GCP) se ver√≠a as√≠:

Ingesta (Reemplazo de ingest.sh):

Un Cloud Scheduler (un cron en la nube) ejecuta una Cloud Function (una mini-funci√≥n sin servidor).

Esta funci√≥n descarga los CSVs y los guarda en un "Data Lake" en Google Cloud Storage (GCS) (un bucket de almacenamiento, como HDFS pero m√°s simple).

Procesamiento (Reemplazo de Spark-Submit):

Usar Dataproc Serverless. Es un servicio que ejecuta tu script de PySpark (process_aeropuertos.py) sin que tengas que configurar un cl√∫ster.

Dataproc lee los CSVs "sucios" de GCS, los procesa (aplicando las mismas reglas) y guarda los datos limpios (en formato Parquet) de nuevo en GCS.

Data Warehouse (Reemplazo de Hive):

Google BigQuery. Es el almac√©n de datos de Google.

Puedes crear una "tabla externa" en BigQuery que lea los archivos Parquet limpios directamente desde GCS.

Todas las consultas SQL que hicimos funcionar√≠an igual (o m√°s r√°pido) en BigQuery.

Orquestaci√≥n (Reemplazo de Airflow):

Cloud Composer. ¬°Es simplemente Airflow, pero administrado por Google! Usar√≠as el mismo DAG que ya tienes.

Ventajas de esta arquitectura Cloud:

Serverless (Sin Servidores): No tienes que administrar m√°quinas virtuales, ni YARN, ni HDFS.

Escalabilidad: Si un d√≠a procesas 100 archivos en lugar de 3, el sistema escala solo.

Costo: Pagas solo por los segundos que tu script de Spark est√° corriendo, no por tener un cl√∫ster encendido 24/7.
