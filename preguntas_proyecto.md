11. Qu√© datos externos agregar√≠a en este dataset que mejorar√≠a el an√°lisis de los datos
Los datos actuales nos dicen qu√© pas√≥, pero no por qu√©. Yo agregar√≠a:

Datos Meteorol√≥gicos (Clima): üå¶Ô∏è Unir por fecha y aeropuerto (local). Esto nos permitir√≠a responder preguntas como: "¬øCu√°ntos vuelos se cancelaron o demoraron por baja visibilidad, viento o lluvia?".

Feriados y Eventos: üìÖ Una tabla simple de fechas (fecha, descripcion_evento). Esto ayudar√≠a a explicar los picos de pasajeros (ej. "Inicio de vacaciones de invierno", "Feriado de Carnaval").

Datos Econ√≥micos (Inflaci√≥n/D√≥lar): üí∏ Unir por fecha. Esto ayudar√≠a a correlacionar la cantidad de pasajeros con el poder adquisitivo. ¬øSube el d√≥lar y bajan los pasajeros?

Detalle de Aeronaves: ‚úàÔ∏è Unir por aeronave. Una tabla que diga la capacidad m√°xima de cada modelo de avi√≥n. Con esto, podr√≠amos calcular el porcentaje de ocupaci√≥n (pasajeros / capacidad_maxima), una m√©trica clave para las aerol√≠neas.

12. Elabore sus conclusiones y recomendaciones sobre este proyecto
Conclusiones:

El stack tecnol√≥gico (Airflow > Spark > Hive) fue validado y demostr√≥ ser robusto para un proceso ETL de Big Data.

La limpieza de datos (Spark) fue esencial: Los datos crudos (CSV) ten√≠an problemas cr√≠ticos que Hive no pod√≠a manejar solo (delimitadores incorrectos, fechas nulas, nombres de columna con espacios). El uso de Spark para transformar los datos fue un √©xito.

Airflow es clave para la automatizaci√≥n: El DAG asegura que el proceso sea repetible, confiable y que cada paso se ejecute en el orden correcto. El historial de logs fue fundamental para la depuraci√≥n.

Hive es una gran capa anal√≠tica: Una vez procesados los datos, Hive nos da el poder de usar SQL para an√°lisis complejos (como los JOINs y GROUP BYs que hicimos) sobre archivos que viven en HDFS.

Recomendaciones:

Monitoreo de Calidad de Datos: Implementar "data checks" en el DAG de Airflow (ej. usando el SQLCheckOperator). Por ejemplo, una tarea que verifique que SUM(pasajeros) sea mayor a cero. Si falla, el DAG se detiene y avisa.

Implementar L√≥gica de Upsert y Validaci√≥n de Unicidad: Modificar el script de Spark para sustituir la escritura directa por una l√≥gica de Merge (Uni√≥n + Ranking por Timestamp) que asegure la unicidad de registros basada en claves primarias. Complementar esto con una tarea de validaci√≥n en Airflow (Quality Gate) que falle el pipeline autom√°ticamente si se detectan inconsistencias o duplicados en la capa final de Hive.

Pasar a Parquet: El script de Spark actualmente guarda en Hive en el formato por defecto (texto). Ser√≠a mucho m√°s eficiente si Spark guardara los datos limpios en formato Parquet (df_vuelos_clean.write.format("parquet")...). Es m√°s r√°pido para consultar y ocupa mucho menos espacio.

1.  Proponer una arquitectura alternativa para este proceso (Cloud)
La arquitectura que use es un "stack" On-Premise cl√°sico. Una alternativa moderna usando Cloud (Google Cloud - GCP) se ver√≠a as√≠:

Ingesta (Reemplazo de ingest.sh):

Un Cloud Scheduler (un cron en la nube) ejecuta una Cloud Function (una mini-funci√≥n sin servidor).

Esta funci√≥n descarga los CSVs y los guarda en un "Data Lake" en Google Cloud Storage (GCS) (un bucket de almacenamiento, como HDFS pero m√°s simple).

Procesamiento (Reemplazo de Spark-Submit):

Usar Dataproc Serverless. Es un servicio que ejecuta tu script de PySpark (process_aeropuertos.py) sin que tengas que configurar un cl√∫ster.

Dataproc lee los CSVs "sucios" de GCS, los procesa (aplicando las mismas reglas) y guarda los datos limpios (en formato Parquet) de nuevo en GCS.

Data Warehouse (Reemplazo de Hive):

Google BigQuery. Es el almac√©n de datos de Google.

Se puede crear una "tabla externa" en BigQuery que lea los archivos Parquet limpios directamente desde GCS.

Todas las consultas SQL que se hicieron igual (o m√°s r√°pido) en BigQuery.

Orquestaci√≥n (Reemplazo de Airflow):

Cloud Composer. Usar√≠a el mismo DAG cambiando ciertos parametros.

Ventajas de esta arquitectura Cloud:

Serverless (Sin Servidores): No hay que administrar m√°quinas virtuales, ni YARN, ni HDFS.

Escalabilidad: Si un d√≠a se procesan 100 archivos en lugar de 3, el sistema escala solo.

Costo: se paga solo por los segundos que el script de Spark est√° corriendo, no por tener un cl√∫ster encendido 24/7.
